{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b9f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1eea210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "cwd = os.getcwd()\n",
    "original_dataset_dir = os.path.join(cwd, \"dataset\")\n",
    "resnet_dataset_dir = os.path.join(cwd, \"resnet_dataset\")\n",
    "efficientnet_dataset_dir = os.path.join(cwd, \"efficientnet_dataset\")\n",
    "\n",
    "# Create directories for new datasets\n",
    "for dataset_dir in [resnet_dataset_dir, efficientnet_dataset_dir]:\n",
    "    for split in [\"train\", \"test\", \"val\"]:\n",
    "        os.makedirs(os.path.join(dataset_dir, split), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a57f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing dataset mappings without headers\n",
    "train_df = pd.read_csv(os.path.join(original_dataset_dir, \"train\", \"train_mapping.csv\"), header=None, names=[\"filename\", \"class\"])\n",
    "test_df = pd.read_csv(os.path.join(original_dataset_dir, \"test\", \"test_mapping.csv\"), header=None, names=[\"filename\", \"class\"])\n",
    "val_df = pd.read_csv(os.path.join(original_dataset_dir, \"val\", \"val_mapping.csv\"), header=None, names=[\"filename\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87552ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization functions\n",
    "def normalize_resnet(image):\n",
    "    image = np.array(image) / 255.0\n",
    "    image = 2 * image - 1                 # [-1, 1]\n",
    "    return Image.fromarray(((image + 1) / 2 * 255).astype(np.uint8))  # back to [0, 255]\n",
    "\n",
    "def normalize_efficientnet(image):\n",
    "    image = np.array(image) / 255.0       # [0, 1]\n",
    "    return Image.fromarray((image * 255).astype(np.uint8))            # back to [0, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "062a52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General processing function\n",
    "def process_images(df, source_dir, dest_dir, split_name, normalize_fn, resize_size, to_rgb=True):\n",
    "    for _, row in df.iterrows():\n",
    "        img_name = row[\"filename\"]\n",
    "        label = str(row[\"class\"])\n",
    "\n",
    "        src_path = os.path.join(source_dir, split_name, img_name)\n",
    "        dest_folder = os.path.join(dest_dir, split_name)\n",
    "        os.makedirs(dest_folder, exist_ok=True)\n",
    "        dest_path = os.path.join(dest_folder, img_name)\n",
    "\n",
    "        # Read and preprocess image\n",
    "        img = Image.open(src_path).convert(\"L\")  # Convert to grayscale\n",
    "        if to_rgb:\n",
    "            img = img.convert(\"RGB\")             # Convert to 3 channels\n",
    "        img = img.resize(resize_size)\n",
    "        img = normalize_fn(img)\n",
    "        img.save(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5460e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet dataset processed and normalized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Process for ResNet: size 224x224, [-1,1]\n",
    "process_images(train_df, original_dataset_dir, resnet_dataset_dir, \"train\", normalize_resnet, resize_size=(224, 224))\n",
    "process_images(test_df, original_dataset_dir, resnet_dataset_dir, \"test\", normalize_resnet, resize_size=(224, 224))\n",
    "process_images(val_df, original_dataset_dir, resnet_dataset_dir, \"val\", normalize_resnet, resize_size=(224, 224))\n",
    "\n",
    "print(\"ResNet dataset processed and normalized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c84880c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet B3 dataset processed and normalized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Process for EfficientNet B3: size 300x300, [0,1]\n",
    "process_images(train_df, original_dataset_dir, efficientnet_dataset_dir, \"train\", normalize_efficientnet, resize_size=(300, 300))\n",
    "process_images(test_df, original_dataset_dir, efficientnet_dataset_dir, \"test\", normalize_efficientnet, resize_size=(300, 300))\n",
    "process_images(val_df, original_dataset_dir, efficientnet_dataset_dir, \"val\", normalize_efficientnet, resize_size=(300, 300))\n",
    "\n",
    "print(\"EfficientNet B3 dataset processed and normalized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6ee8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mapping CSV to C:\\Users\\Safi\\Desktop\\Masters\\UTArlington\\Sem2\\ML\\Project\\resnet_dataset\\train\\train_mapping.csv\n",
      "Saved mapping CSV to C:\\Users\\Safi\\Desktop\\Masters\\UTArlington\\Sem2\\ML\\Project\\resnet_dataset\\test\\test_mapping.csv\n",
      "Saved mapping CSV to C:\\Users\\Safi\\Desktop\\Masters\\UTArlington\\Sem2\\ML\\Project\\resnet_dataset\\val\\val_mapping.csv\n",
      "Saved mapping CSV to C:\\Users\\Safi\\Desktop\\Masters\\UTArlington\\Sem2\\ML\\Project\\efficientnet_dataset\\train\\train_mapping.csv\n",
      "Saved mapping CSV to C:\\Users\\Safi\\Desktop\\Masters\\UTArlington\\Sem2\\ML\\Project\\efficientnet_dataset\\test\\test_mapping.csv\n",
      "Saved mapping CSV to C:\\Users\\Safi\\Desktop\\Masters\\UTArlington\\Sem2\\ML\\Project\\efficientnet_dataset\\val\\val_mapping.csv\n",
      "All mapping CSVs added to each split folder.\n"
     ]
    }
   ],
   "source": [
    "# Copy mapping CSVs into each split folder for both datasets\n",
    "split_csvs = {\n",
    "    \"train\": train_df,\n",
    "    \"test\": test_df,\n",
    "    \"val\": val_df\n",
    "}\n",
    "\n",
    "for dataset_dir in [resnet_dataset_dir, efficientnet_dataset_dir]:\n",
    "    for split, df in split_csvs.items():\n",
    "        csv_path = os.path.join(dataset_dir, split, f\"{split}_mapping.csv\")\n",
    "        df.to_csv(csv_path, index=False, header=False)\n",
    "        print(f\"Saved mapping CSV to {csv_path}\")\n",
    "\n",
    "print(\"All mapping CSVs added to each split folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb9a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
